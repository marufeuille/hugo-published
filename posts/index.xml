<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on なんとなくブログ</title>
    <link>https://blog.marufeuille.dev/posts/</link>
    <description>Recent content in Posts on なんとなくブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>marufeuille</copyright>
    <lastBuildDate>Sat, 10 Sep 2022 21:00:00 +0900</lastBuildDate><atom:link href="https://blog.marufeuille.dev/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fivetran を触ってみて思ったことたち</title>
      <link>https://blog.marufeuille.dev/posts/fivetran_with_dbt/</link>
      <pubDate>Sat, 10 Sep 2022 21:00:00 +0900</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/fivetran_with_dbt/</guid>
      <description>はじめに 前回に引き続きELツールであるFivetranを試しており、ちょいちょい触って気づいたことを書き留めておきます
所感 通知 エラー時の通知などは見た限りはメールのみに対応しています。Slack等には直接は送れなさそうです。この点はUIからだけの操作を考えるとツライかも。
今どきメールで拾いたいっていうニーズのほうが少なそうだが、逆にライトに使う層だとそれでも良い気がするので、そういうことなのだろうか。
ログの転送 fivetran自体のログはWebUIから確認も可能ですが、Datadog, GCP Cloudloggingのような一般的なログ管理ソリューションに転送可能です。
先程の通知のところでメールのみと書きましたが、他のログ管理ソリューションに転送できればあとは大体やりたい放題ですね！
dbt連携 まだベータですが個人的には結構良い感触を持ちました。
特にどちらも比較的価格は安いソリューションでありつつ、インフラを意識しないので最少人数で分析基盤を作っていくみたいなところでは結構良さそうです。
今回はオープンデータから稲作に関するデータと天気情報を持ってきてゴニョろうとする、みたいなデモを作ってみました。
生データをlakeにいれ、少し加工したものをwarehouse、分析に使う段をmartとわけてます。
fivetran内の転送タスクに合わせて実行ができてワークフローが一定不要 上流のコネクタの実行に合わせて勝手に後続のdbtのタスクを流すことができます。 つまり、凝ったことをしなければワークフローの管理が不要ということですね。楽や・・・
もちろん、必要に応じてスケジュールの設定もできます。
リネージュがソースからdbt内まで追える こんな感じでソースからmartまでいい感じに可視化できました。
ineが稲作データですが、面倒になったのでwarehouse部分はすっ飛ばしてるのはご愛嬌。
fivetran内で全体のリネージュが出てくるので良いですね。
dbtのログもちゃんと拾える (転送設定の上で)cloudlogging上で確認したのですが、例えば成功時のログは以下のようにjsonで構造化されてcloudlogginから確認できます。
ちゃんと構造化されているので、サクッとメトリックを作ったり通知するのもやりやすそうに見えます。
{ &amp;quot;insertId&amp;quot;: &amp;quot;9g7n20g1atrvd6&amp;quot;, &amp;quot;jsonPayload&amp;quot;: { &amp;quot;event&amp;quot;: &amp;quot;dbt_run_succeeded&amp;quot;, &amp;quot;created&amp;quot;: &amp;quot;2022-09-10T07:14:44.435Z&amp;quot;, &amp;quot;data&amp;quot;: { &amp;quot;startTime&amp;quot;: &amp;quot;2022-09-10T07:14:17.900Z&amp;quot;, &amp;quot;result&amp;quot;: { &amp;quot;stepResults&amp;quot;: [ { &amp;quot;step&amp;quot;: { &amp;quot;processBuilderCommand&amp;quot;: [ &amp;quot;dbt&amp;quot;, &amp;quot;test&amp;quot;, &amp;quot;--models&amp;quot;, &amp;quot;+sunshine_time&amp;quot;, &amp;quot;+temperature&amp;quot; ], &amp;quot;name&amp;quot;: &amp;quot;Scheduled: Test&amp;quot; }, &amp;quot;failedModelRuns&amp;quot;: 0, &amp;quot;successfulModelRuns&amp;quot;: 0, &amp;quot;success&amp;quot;: true, &amp;quot;commandResult&amp;quot;: { &amp;quot;error&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;exitCode&amp;quot;: 0, &amp;quot;output&amp;quot;: &amp;quot;07:14:39 Running with dbt=1.</description>
    </item>
    
    <item>
      <title>FivetranをTerraformで構成する方法</title>
      <link>https://blog.marufeuille.dev/posts/fivetran_with_terraform/</link>
      <pubDate>Thu, 08 Sep 2022 21:00:00 +0900</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/fivetran_with_terraform/</guid>
      <description>はじめに ELツールであるFivetranを試す機会があり、terraformも使えるということでどこまで使えるのか試してみました
構成 データの転送は CloudSQL(GCP) -&amp;gt; Fivetran -&amp;gt; BigQuery という経路で行うことにしました。
CloudSQLの準備 CloudSQLはコンソール上から適当に作成しています。 その上でデータは面倒だったのでこの手順で用意し、その上で以下のようにしてユーザを作成します。
CREATE USER &#39;fivetran&#39;@&#39;%&#39; IDENTIFIED BY &#39;ぱすわーど&#39; GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO &#39;fivetran&#39;@&#39;%&#39; Terraform  provider.tf  api_key, api_secretはWebUI上から発行しておいてください    1terraform { 2 required_providers { 3 fivetran = { 4 source = &amp;#34;fivetran/fivetran&amp;#34; 5 version = &amp;#34;0.6.3&amp;#34; 6 } 7 } 8} 91011provider &amp;#34;fivetran&amp;#34; { 12 api_key = &amp;#34;APIKEY&amp;#34; 13 api_secret = &amp;#34;APISECRET&amp;#34; 14}  main.</description>
    </item>
    
    <item>
      <title>Pytest</title>
      <link>https://blog.marufeuille.dev/posts/pytest/</link>
      <pubDate>Sun, 10 Jul 2022 22:29:17 +0000</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/pytest/</guid>
      <description>はじめに pytestの書き方をよく忘れるのでまとめておく
なお、自分が思っている使い方的な側面もあるので必ずしもこの書き方でなくて良いし、もっと良い書き方があるかもしれない。
気づいたときに追記していきます。
使い方色々 Mockオブジェクトを作成する Pythonなので、適当なオブジェクトを作ってMockとして呼び出すということも可能だが、管理が面倒なので基本はMagicMockして作れば良い。
1mocked = MagicMock(spec=...) 属性値のMockをする PropertyMockを使えば良い
1from unittest.mock import PropertyMock 2 3from google.cloud import storage 4 5def test_hoge(): 6 mocked_blob = MagicMock(spec=storage.Blob) 7 suze = PropertyMock(return_value=10) 8 type(mocked_blob).size = size mockに対してではなく、mockのtypeに対して設定するのがミソである。
インポートされたパッケージ内の特定のクラスをモックしたい モックをするときはpatchを使って基本的に以下のような形でできる
1from unittest.mock import patch 2 3... 4 5def test_hoge(): 6 ... 7 with patch(..., autospec=True) as mocked: 8 ... 9 このpatchに何を指定するかがちょっと悩みがちだが、その名前空間におけるオブジェクトを上書きするみたいな気持ちでやると良い。
例えば、hoge/fuga/main.pyで定義されるモジュールがあったときに、以下のようにしてimport 文が書かれていたとする
1from google.cloud import storage これの storage.Client をモックしたいとしたときは
1from unittest.</description>
    </item>
    
    <item>
      <title>CloudBuild内でビルドするコンテナ内からプライベートリポジトリを参照する方法</title>
      <link>https://blog.marufeuille.dev/posts/docker_build_with_ssh/</link>
      <pubDate>Mon, 27 Jun 2022 21:51:40 +0900</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/docker_build_with_ssh/</guid>
      <description>結論   先日、cloudbuild上でdocker buildするときに--sshを渡す方法だとうまく動作しないと書きましたが、再検証したら動いたのでメモします。
  おそらく、known_hostsを追加していなかったとかそんな感じだと思われます・・・ださい。
  追検証の体なので、そういう形式で書いていますので、結論だけ知りたい方は最下部に行ってください。
  検証ログ on Local 適当なプライベートリポジトリ marufeuille/privare_repository_test を用意しローカル環境で以下を実行すると問題なくクローンできます（公開鍵は設定済みです）
# git clone git@github.com:marufeuille/privare_repository_test.git Cloning into &#39;privare_repository_test&#39;... remote: Enumerating objects: 3, done. remote: Counting objects: 100% (3/3), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (3/3), done. では、このRepositoryを docker build 時にcloneすることを考えます。
次のようなDockerfileを考えます。
FROM ubuntu:22.04 RUN apt update &amp;amp;&amp;amp; apt install -y openssh-client git RUN git clone git@github.</description>
    </item>
    
    <item>
      <title>CloudBuild内でビルドするコンテナ内のpoetryからプライベートリポジトリを参照する方法</title>
      <link>https://blog.marufeuille.dev/posts/poetry_private_repository_on_docker_on_cloudbuild/</link>
      <pubDate>Sun, 26 Jun 2022 06:23:54 +0900</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/poetry_private_repository_on_docker_on_cloudbuild/</guid>
      <description>注意事項 その後の検証で --ssh オプションでも同等に動作することの検証が取れたのでこちらを参照してください。
はじめに 長いタイトルになってしまいましたが、表題のとおりです笑
cloudbuild内でプライベートリポジトリを参照する方法も、docker build内でプライベートリポジトリを参照する方法もどちらも色々と記事があったのですが、併せると中々なかったのでメモしておきます
やったこと 結論 ざっくりいうと、以下のようにすれば動きます。
ポイントは
 private repositoryの秘密鍵はSecretManager経由で渡す docker buildはBUILDKITを有効化した上で、秘密鍵を&amp;ndash;secretオプションでマウントする Dockerfile内では--mountオプションで秘密鍵を利用する  1steps: 2- name: &amp;#39;gcr.io/cloud-builders/git&amp;#39; 3 secretEnv: [&amp;#39;SSH_KEY&amp;#39;] 4 entrypoint: &amp;#39;bash&amp;#39; 5 args: 6 - -c 7 - |8echo &amp;#34;$$SSH_KEY&amp;#34; &amp;gt;&amp;gt; /root/.ssh/id_rsa 9chmod 400 /root/.ssh/id_rsa 10ssh-keyscan -t rsa github.com &amp;gt; /root/.ssh/known_hosts 11 volumes: 12 - name: &amp;#39;ssh&amp;#39; 13 path: /root/.ssh 14 15- name: gcr.io/cloud-builders/docker:latest 16 dir: k8s_pipelines 17 entrypoint: bash 18 args: 19 - -c 20 - |-21set -eux 22docker build --secret id=ssh,src=https://blog.marufeuille.dev/root/.</description>
    </item>
    
    <item>
      <title>First Posts</title>
      <link>https://blog.marufeuille.dev/posts/first-posts/</link>
      <pubDate>Sat, 25 Jun 2022 21:17:22 +0900</pubDate>
      
      <guid>https://blog.marufeuille.dev/posts/first-posts/</guid>
      <description>hi there</description>
    </item>
    
  </channel>
</rss>
